"10,000-19,999",
"20,000-29,999",
"More than 30,000")),
`Scholar Status` = as.factor(`Scholar Status`),
`Scholar Secondary Status` = as.factor(`Scholar Secondary Status`),
`6 Months Post College: Employment Status` = as.factor(`6 Months Post College: Employment Status`),
`6 Months Post College: Graduate School` = as.factor(`6 Months Post College: Graduate School`)) %>%
mutate(IvyPlus = ifelse(`Scholar College` %in% c("Brown University", "Columbia University",
"Cornell University", "Dartmouth College",
"Harvard University", "University of Pennsylvania",
"Princeton University", "Yale University",
"Stanford", "Massachusetts Institute of Technology",
"University of Chicago", "Duke University" ), 1, 0)) %>%
filter(!`Scholar Secondary Status` %in% c("Did Not Renew", "Break/Suspension")) %>%
filter(`Scholar Status` == "Scholar Alumni" | (`Last Renewal Date` %in% c("2019 Spring", "2019 Fall", NA) &
`Scholar Status` == "Current Scholar")) %>%
left_join(SAT_percentile_historic, by = c("SAT Total" = "SAT Composite Score", "Cohort" = "Cohort")) %>%
mutate(`SAT Group` = cut(`SAT Percentile`,
breaks= c(-Inf, 49, 79, Inf),
labels = c("<50th",
"50th-80th",
">80th")),
`College Forbes Ranking 2018` = as.numeric(`College Forbes Ranking 2018`))
#render site.
rmarkdown::render_site()
wd()
getwd()
setwd("/Users/jcrouser/Google Drive/Teaching/Course Material/CSC235")
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
install.packages("markdown")
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/Users/jcrouser/Google Drive/Teaching/Course Material/CSC250/CSC250-website")
#render site.
rmarkdown::render_site()
getwd()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/Users/jcrouser/Google Drive/Teaching/Course Material/CSC250/CSC250-website")
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
setwd("/Users/jcrouser/Google Drive/Teaching/Course Material/CSC235")
#render site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/Users/jcrouser/Google Drive/Teaching/Course Material/CSC250/CSC250-website")
#render site.
rmarkdown::render_site()
#render site.
rmarkdown::render_site()
View(SAT_percentile_historic)
library(readr)
teaching2021_2022 <- read_csv("~/Downloads/Teaching Preferences for 2021-2022 (Responses) - Form Responses 1.csv")
View(teaching2021_2022)
View(teaching2021_2022)
library(tidyr)
t(teaching2021_2022)
library(tidyr)
teaching2021_2022_r <- t(teaching2021_2022)
library(tidyr)
teaching2021_2022_r <- rotate_df(teaching2021_2022)
library
library(data.table)
teaching2021_2022_r <- transpose(teaching2021_2022)
View(teaching2021_2022_r)
library
library(data.table)
teaching2021_2022_r <- transpose(teaching2021_2022)
setnames(teaching2021_2022_r, rownames(teaching2021_2022))
library(dplyr)
teaching2021_2022 %>%
select(-c(25:27)) %>%
pivot_longer()
library(dplyr)
teaching2021_2022 %>%
select(!!c(25:27)) %>%
pivot_longer()
library(dplyr)
teaching2021_2022 %>%
select(25:27) %>%
pivot_longer()
?select
library(dplyr)
teaching2021_2022 %>%
select(last_col())
?last_col
library(dplyr)
teaching2021_2022 %>%
select(email, last_col())
library(dplyr)
teaching2021_2022 %>%
select(`Email Address`, last_col())
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[:-4]
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,:-4]
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24]
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")
View(courses_by_person)
?nest
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest(courses)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest(courses) %>%
pivot_wider(names_from = value)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest(courses) %>%
pivot_wider(names_from = "value")
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest(courses) %>%
pivot_wider(names_from = values, values_from = data)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest(courses)
library(readr)
teaching2021_2022 <- read_csv("~/Downloads/Teaching Preferences for 2021-2022 (Responses) - Form Responses 1.csv")
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest(courses)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
nest(courses) %>%
pivot_wider(names_from = values, values_from = data)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
nest(courses) %>%
pivot_wider(names_from = value, values_from = data)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
nest(courses) %>%
pivot_wider(names_from = value, values_from = data) %>%
select(-NA)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
nest(courses) %>%
pivot_wider(names_from = value, values_from = data) %>%
select(-`NA`)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
nest(courses) %>%
pivot_wider(names_from = value, values_from = data) %>%
select(-`NA`) %>%
left_join(comments_by_person)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
nest(courses) %>%
pivot_wider(names_from = value, values_from = data) %>%
select(-`NA`) %>%
left_join(comments_by_person, by = "Email Address")
write_csv(courses_by_person, "teaching2021-2022.csv")
write_csv(courses_by_person)
write_csv(courses_by_person, path = "teaching2021-2022.csv")
library(dplyr)
preferences_by_course <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")
View(teaching2021_2022)
library(dplyr)
comments_by_person <- teaching2021_2022 %>%
select(`Email Address`, last_col())
courses_by_person <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses")  %>%
summarise(courses) %>%
pivot_wider(names_from = value, values_from = data) %>%
select(-`NA`) %>%
left_join(comments_by_person, by = "Email Address")
View(preferences_by_course)
library(dplyr)
preferences_by_course <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest("Email Address")
library(dplyr)
preferences_by_course <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "courses") %>%
nest("Email Address") %>%
filter(!is.na(value))
library(dplyr)
preferences_by_course <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "Course") %>%
nest("Email Address") %>%
filter(!is.na(value)) %>%
sort(Course)
library(dplyr)
preferences_by_course <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "Course") %>%
nest("Email Address") %>%
filter(!is.na(value)) %>%
arrange(Course)
library(dplyr)
preferences_by_course <- teaching2021_2022[,1:24] %>%
pivot_longer(-1, names_to = "Course") %>%
nest("Email Address") %>%
filter(!is.na(value)) %>%
pivot_wider(names_from = value, values_from = data) %>%
arrange(Course)
ibrary(rvest)
library(rvest)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1[-(1:2), ]
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page2 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_mortality_rate")
page2 <- html_table(html_nodes(page2, ".wikitable")[1], fill = TRUE)[[1]]
page2 <- page2[-(1:2), ]
page2[, -1] <- sapply(page2[, -1], as.numeric)
names(page2)[1] <- "country"
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3[-(1:2),]
page3 <- page3[, c(1:3,5)]
page3[, 2:3] <- sapply(page3[, 2:3], as.numeric)
## Warning in lapply(X = X, FUN = FUN, ...): NAs introduced by coercion
names(page3)[1] <- "country"
names(page3)[4] <- "region"
library(stringr)
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata$region <- str_replace_all(countrydata$region,
str_c("Central |Middle |Eastern |Western |",
"South_Eastern |Southern |Northern |South-"),
"")
countrydata$region <- str_replace(countrydata$region, "Melanesia", "Asia")
countrydata$region <- str_replace(countrydata$region, "Caribbean", "America")
countrydata$region <- str_replace(countrydata$region, "^America$", "North America")
countrydata <- countrydata[, c(1, 18, 4:9, 12:16)]
View(countrydata)
library(rvest)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1[-(1:2), ]
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page2 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_mortality_rate")
page2 <- html_table(html_nodes(page2, ".wikitable")[1], fill = TRUE)[[1]]
page2 <- page2[-(1:2), ]
page2[, -1] <- sapply(page2[, -1], as.numeric)
names(page2)[1] <- "country"
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3[-(1:2),]
page3 <- page3[, c(1:3,5)]
page3[, 2:3] <- sapply(page3[, 2:3], as.numeric)
## Warning in lapply(X = X, FUN = FUN, ...): NAs introduced by coercion
names(page3)[1] <- "country"
names(page3)[4] <- "region"
library(stringr)
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata$region <- str_replace_all(countrydata$region,
str_c("Central |Middle |Eastern |Western |",
"South_Eastern |Southern |Northern |South-"),
"")
countrydata$region <- str_replace(countrydata$region, "Melanesia", "Asia")
countrydata$region <- str_replace(countrydata$region, "Caribbean", "America")
countrydata$region <- str_replace(countrydata$region, "^America$", "North America")
countrydata <- na.omit(countrydata)
head(countrydata)
library(rvest)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1[-(1:2), ]
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page2 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_mortality_rate")
page2 <- html_table(html_nodes(page2, ".wikitable")[1], fill = TRUE)[[1]]
page2 <- page2[-(1:2), ]
page2[, -1] <- sapply(page2[, -1], as.numeric)
names(page2)[1] <- "country"
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3[-(1:2),]
page3 <- page3[, c(1:3,5)]
page3[, 2:3] <- sapply(page3[, 2:3], as.numeric)
## Warning in lapply(X = X, FUN = FUN, ...): NAs introduced by coercion
names(page3)[1] <- "country"
names(page3)[4] <- "region"
library(stringr)
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata$region <- str_replace_all(countrydata$region,
str_c("Central |Middle |Eastern |Western |",
"South_Eastern |Southern |Northern |South-"),
"")
countrydata$region <- str_replace(countrydata$region, "Melanesia", "Asia")
countrydata$region <- str_replace(countrydata$region, "Caribbean", "America")
countrydata$region <- str_replace(countrydata$region, "^America$", "North America")
countrydata <- countrydata[, c(1, 18, 4:9, 12:16)]
library(rvest)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1[-(1:2), ]
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page2 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_mortality_rate")
page2 <- html_table(html_nodes(page2, ".wikitable")[1], fill = TRUE)[[1]]
page2 <- page2[-(1:2), ]
page2[, -1] <- sapply(page2[, -1], as.numeric)
names(page2)[1] <- "country"
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3[-(1:2),]
page3 <- page3[, c(1:3,5)]
page3[, 2:3] <- sapply(page3[, 2:3], as.numeric)
## Warning in lapply(X = X, FUN = FUN, ...): NAs introduced by coercion
names(page3)[1] <- "country"
names(page3)[4] <- "region"
library(stringr)
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata$region <- str_replace_all(countrydata$region,
str_c("Central |Middle |Eastern |Western |",
"South_Eastern |Southern |Northern |South-"),
"")
countrydata$region <- str_replace(countrydata$region, "Melanesia", "Asia")
countrydata$region <- str_replace(countrydata$region, "Caribbean", "America")
countrydata$region <- str_replace(countrydata$region, "^America$", "North America")
countrydata <- na.omit(countrydata)
View(page1)
View(page2)
View(page3)
library(rvest)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1[-(1:2), ]
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page2 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_mortality_rate")
page2 <- html_table(html_nodes(page2, ".wikitable")[1], fill = TRUE)[[1]]
page2 <- page2[-(1:2), ]
page2[, -1] <- sapply(page2[, -1], as.numeric)
names(page2)[1] <- "country"
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3[-(1:2),]
page3 <- page3[, c(1:3,5)]
page3[, 2:3] <- sapply(page3[, 2:3], as.numeric)
## Warning in lapply(X = X, FUN = FUN, ...): NAs introduced by coercion
names(page3)[1] <- "country"
names(page3)[4] <- "region"
library(stringr)
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata$region <- str_replace_all(countrydata$region,
str_c("Central |Middle |Eastern |Western |",
"South_Eastern |Southern |Northern |South-"),
"")
View(countrydata)
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
countrydata$region <- str_replace_all(countrydata$region,
str_c("Central |Middle |Eastern |Western |",
"South_Eastern |Southern |Northern |South-"),
"")
countrydata$region <- str_replace(countrydata$region, "Melanesia", "Asia")
countrydata$region <- str_replace(countrydata$region, "Caribbean", "America")
countrydata$region <- str_replace(countrydata$region, "^America$", "North America")
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
View(page3)
page2 <- page2[-(1:2), ]
View(page3)
page3 <- page3[, c(1:3,5)]
page3[, 2:3] <- sapply(page3[, 2:3], as.numeric)
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3[-(1:2),]
page3 <- page3[, c(1:3,5)]
page3[, 4] <- sapply(page3[, 4], as.numeric)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1 %>%
select(-c(1,2))
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1[-(1:2), ]
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1 %>%
slice(2:n())
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1 %>%
slice(3:n())
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1 %>%
slice(3:n())
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page3 <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_intentional_homicide_rate")
page3 <- html_table(html_nodes(page3, ".wikitable")[3], fill = TRUE)[[1]]
page3 <- page3 %>%
slice(3:n())
page3 <- page3[, c(1:3,5)]
page3[, 4] <- sapply(page3[, 4], as.numeric)
library(rvest)
library(tidyr)
page1 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate")
page1 <- html_table(html_nodes(page1, ".wikitable")[1], fill = TRUE)[[1]]
page1 <- page1 %>%
slice(3:n())
page1[, -1] <- sapply(page1[, -1], as.numeric)
names(page1)[1] <- "country"
page2 <- read_html("https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_mortality_rate")
page2 <- html_table(html_nodes(page2, ".wikitable")[1], fill = TRUE)[[1]]
page2 <- page2 %>%
slice(3:n())
countrydata <- Reduce(function(...) merge(..., by = "country", all = TRUE),
list(page1, page2, page3))
